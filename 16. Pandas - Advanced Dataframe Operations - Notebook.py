# -*- coding: utf-8 -*-
"""Notebook.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/AI-Core/Content-Public/blob/main/Content/units/Data-Handling/2.%20Data%20Manipulation%20with%20Pandas/3.%20Pandas%20-%20Advanced%20Dataframe%20Operations/Notebook.ipynb

# Pandas - Advanced Dataframe Operations

Now that we are familiar with Pandas and dataframes, let's take a deeper dive into some advanced operations we can do.

## NoneType

- We must distinguish between `None`, `0` and `NaN` here
    - `None` has the data type 'NoneType' and is therefore a value, and we can use this as a placeholder before adding values
    - `0` is an integer, and therefore a value, this shows that we have a response in the cell, but the response is 0
    - `NaN` stands for 'Not a Number' and so denotes a MISSING value, although it has the type float
- We can see this clearly when we check the types of each:
"""

type(None)

type(0)

import numpy as np

type(np.nan)
np.nan + float("inf")

"""## Adding and Removing Columns

So far, we have created new columns based on the values of other columns. But, we can create columns with any values we want. For example, let's say that I want to create an empty column (with `None` values).

You can simply index the name of the column, and assign a value. All samples in the column will get the same value. 

_Note: Be careful here! If the name of the column exists, it will overwrite the whole column_
"""

# This will create a new column with a single value inc. integer/string/NoneType

sf_sal["new col"] = None

sf_sal.head() # shows the first 5 entries (the head) of the dataframe

"""If you want to remove rows or columns, you can use the `drop` method. This method accepts the name of the rows or the columns you want to remove. You can pass a single row or column, or a list of the rows or columns you want to remove. For example, if we want to remove the row corresponding to index "AB" 

"""

sf_sal.drop("AB").head(5)

"""Or if you want to remove "AB", "AC", and "AD"
"""

sf_sal.drop(["AB", "AC", "AD"]).head()

"""By default, `drop` will remove rows based on the argument you passed. So, if you pass the name of the column and don't add additional arguments, it will throw an error (unless the dataframe contains a row and a column with the same name)

So, if you want to drop a column you need to change the `axis` argument to `1`.

Let's say that we want to remove the "Status" column:
"""

sf_sal.drop("Status")

"""Observe the error. Pandas is complaining because there is no "Status" in the rows. So, if we specify the axis to find "Status", let's see the difference:"""

sf_sal.drop("Status", axis=1).head(3)

"""Notice that we have dropped "AB", "AC", and "AD" in an earlier example. But they are still there!

The drop method, by default, is not an "In place" method. That means that it will not change the content of the original dataframe.

If you want to change its original content, you can use the `inplace` argument and set it to `True`.

<font size=+0.75> Don't run this cell yet!</font>
"""

sf_sal.drop("Status", axis=1, inplace=True)

"""_Note: If we run the above cell, we will change the original status of the dataframe, and it would be irreversible. A better idea would be creating a copy of this dataframe and apply those changes to it._

However, we can't simply say `sf_sal_copy = sf_sal` because any operation we perform on the copy would affect the original as well.

Check the following [page](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.dataframe.drop.html) to know more about the `drop` method

## `copy()`

In many programming languages, when you assign a value to a variable, that variable is going to point to a new space in memory. Remember that assigning a list to a new variable will make the new variable point to the same space in memory that the original list was pointing to.

When dealing with dataframes, it's quite common that you have to create new dataframes based on existing ones. And if you change the value of the new dataframe, the original dataframe will be affected.

In order to avoid it, you can use the `copy()` method that will create a copy of the original dataframe:
"""

sf_copy = sf_sal.copy()

"""Now, we can remove the "Status" column with no consequences on sf_sal"""

sf_copy.drop("Status", axis=1, inplace=True)
sf_copy.head()

"""## `.loc` and `.iloc`

We saw that we can index columns to a dataframe to obtain parts of that dataframe. However, a more common way to get values from a dataframe is using the `.loc` and `.iloc` properties

`.loc` will select rows or columns based on their names. For example, row "AB" can be accessed using `loc["AB"]`. However, if you want to get an entire column, for example "JobTitle", you can't use `loc["JobTitle"]`. To do so you can either:
- `sf_sal["JobTitle]`
- `sf_sal.loc[:, "JobTitle"]` where the colon (`:`) indicates ALL rows
"""

# use .loc[] to select rows by row names and columns by column names
print(sf_sal.loc["AB"])
sf_sal.loc[:, "JobTitle"].head(3)

"""So, you can combine them using `["row name", "column name"]`. For example, let's say that you want to see the "JobTitle" of the sample corresponding to "FG". Easy:"""

sf_sal.loc["FG", "JobTitle"]

"""If you don't care too much about the index name, you can use `iloc` which will perform the same operation, but it will use numerical indices. """

print(sf_sal.iloc[0])
print(sf_sal.iloc[0, 1])

"""You can also obtain subsets using `loc` and `iloc`"""

# for subset of rows and columns, use lists of each within .loc[]
# can index out of order

sf_sal.loc[["AC", "CV", "BK"],["BasePay", "Surname", "Year"]]

"""### Comparing Dates in ISO format

ISO 8601 is an internationally recognised way to compare dates and times, it solves the problem of comparing exact times and dates across timezones. In the case of time they are represented by hours-minutes-seconds and for years year-month-day. So "September 17th 2021" would be written as 2021-09-17 or without the delimiter "-" as 20210917. With the time added the general format is `20210917 18:16:11` which would represent 17th September 2021 at 16 minutes and 11 seconds past 6. 

The next table shows how each value range should be represented:


| Format according to ISO 8601  | Value ranges |
|---|---|
|  Year (Y) | YYYY, four-digit, abbreviated to two-digit  |
| Month (M)  | MM, 01 to 12  |
| Month name (B)  | Jan to Dec |
| Week (W)  |  WW, 01 to 53 |
| Day (D)  |  D, day of the week, 1 to 7 |
| day (d)  |  d, day of the month, 1 to 31 |
| Hour (h)  |  hh, 00 to 23, 24:00:00 as the end time |
|  Minute (m) | 	mm, 00 to 59  |
|  Second (s) |  ss, 00 to 59 |
| Decimal fraction (f)  | Fractions of seconds, any degree of accuracy  |

A full list of format codes to convert strings can be found at the bottom of the `datetime` documentation [here](https://docs.python.org/3/library/datetime.html).

Creating a date in non ISO format you can see that we don't get the expected result:
"""

later_date_non_ISO = "February 17th 2021"
earlier_date_non_ISO = "January 16th 2000"

print(later_date_non_ISO < earlier_date_non_ISO)
print(later_date_non_ISO > earlier_date_non_ISO)

later_date_ISO_format = "2021-02-17"
earlier_date_ISO_format = "2021-02-16"

print(later_date_ISO_format < earlier_date_ISO_format)
print(later_date_ISO_format > earlier_date_ISO_format)

"""And comparing times on the same day only a millisecond apart:"""

later_date_ISO_format = "2021-02-16 11:01:11:10"
earlier_date_ISO_format = "2021-02-16 11:01:11:09"
print(later_date_ISO_format < earlier_date_ISO_format)
print(later_date_ISO_format > earlier_date_ISO_format)

"""You can also use Python's built-in library `datetime` to convert a date string easily to a date object using the `strptime` method for an easy comparison of dates. 

The `strptime` method takes two arguments:
- The string to convert to `datetime`
- The format code


"""

from datetime import datetime

non_ISO_datestring_one = "17 February, 1999"
non_ISO_datestring_two = "17/02/1999 18:40:02"
print(type(non_ISO_datestring_one))

datestring_one_ISO_format = datetime.strptime(non_ISO_datestring_one, "%d %B, %Y")
datestring_two_ISO_format = datetime.strptime(non_ISO_datestring_two, "%d/%m/%Y %H:%M:%S")
print(type(datestring_one_ISO_format))

print(datestring_one_ISO_format)
print(datestring_two_ISO_format)

print(datestring_one_ISO_format < datestring_two_ISO_format)

"""When cleaning data using Pandas you might run into this issue where the dates in your dataframe are in non-ISO format. Let's look at how we can solve this problem by converting the dates to the correct format using the Pandas `to_datetime` method."""

# Creating our dataframe

data = {"Date" : ["17 February, 2021", "21 September, 2000", "18 August, 1956"],
        "DOB" : ["17/02/2021", "21/09/2000", "18/08/1956"],
        "Flight_Departure" : ["17/02/2021 18:02:01", "10/02/2010 19:01:11", "01/07/1998 11:02:56"]}

df = pd.dataframe(data)
df

"""We can use the `format` argument to specify the format code as before:"""

# Convert the dates to ISO format

df["Date"] = pd.to_datetime(df["Date"], format="%d %B, %Y")
df["DOB"] = pd.to_datetime(df["DOB"], format="%d/%m/%Y")
df["Flight_Departure"] = pd.to_datetime(df["Flight_Departure"], format="%d/%m/%Y %H:%M:%S")
df

"""## Conditional Selection

What if you wanted to obtain those samples that meet certain requirements? For example, we want to see how many people have a "TotalPay" greater than 30000. 

Similar to Numpy, Pandas will apply a comparison operator to all the dataframe elements.
"""

# boolean condition like this returns boolean applied to each value in the column (like NumPy)

sf_sal["TotalPay"] > 300000

"""The output of the comparison is also named <font size=+0.5> __mask__ </font>

You can use a mask to filter dataframes just by indexing that mask to the dataframe. For example, if we assign that mask to a variable, and then we index the mask to the original dataframe, let's see what happens:
"""

# can index dataframe using this boolean to return only rows where this is true (called boolean masking)

mask = sf_sal["TotalPay"] > 300000

sf_sal_mask = sf_sal[mask]
sf_sal_mask

"""Observe that all the samples in the dataframe have a "TotalPay" greater than 30000

You can also write the mask within the square brackets to save lines of code!
"""

sf_sal[sf_sal["TotalPay"] > 300000]

"""### Try it out
- Use what you have just learned about conditional selection to find the following:

1. A dataframe containing the Name, Total Pay (with Benefits), Job Title and Base Pay of the employee named 'Albert Pardini'.

2. The highest paid person in terms of Base Pay. (look up the .max() method) `max(sf_sal["BasePay"])`

## Set and Reset Index
"""

# use .reset_index() to revert to original numerical index (must specify inplace=True)

sf_sal.reset_index()

sf_sal.reset_index(inplace=True)

sf_sal

# Use .set_index() to change the index to a column

sf_sal.set_index("Id")

"""## Key Takeaways

- Although they may appear similar to each one, `None`, `NaN` and `0` are actually quite different:
	- `None` is a value
	- `NaN` is used to indicate a missing value
	- `0` is an integer
- In order to drop one or more columns in a dataframe, the `.drop()` command can be used along with the column name(s)
- The `.copy()` command can be used to create a copy of an existing dataframe. This is useful to avoid applying any changes to the data stored in the original dataframe.
- To select specific rows or columns by using their names, the `.loc()` command can be used
- `.,iloc()` behaves similarly to `.loc()`, however it takes a numerical value for the index rather than a text name
- You can use Python's built-in `datetime` library to format a date string easily into a date object that we can then use in our code
- Pandas provides the capability to apply conditional select commands such as greater than `>`, less than `<`, and equal to `=` on values stored in dataframes
- The `.set_index()` command can be used to change an index to a particular column


## Further reading
- More details on pandas operations are available in pandas documentation: https://pandas.pydata.org/docs/
"""