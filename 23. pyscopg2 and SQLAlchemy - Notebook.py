# -*- coding: utf-8 -*-
"""Notebook.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/AI-Core/Content-Public/blob/main/Content/units/Data-Handling/3.%20SQL/7.%20pyscopg2%20and%20SQLAlchemy/Notebook.ipynb

# Psycopg2 and SQLAlchemy

We have seen how to make queries using pgAdmin4. We can go to the same platform and export the output of out query into a CSV:

![](https://github.com/AI-Core/Content-Public/blob/main/Content/units/Data-Handling/3.%20SQL/7.%20pyscopg2%20and%20SQLAlchemy/images/pgadmin_exportCSV.png?raw=1)

But this defeats the purpose of making everything simple and automated... We would need to 1) make the query, 2) export it into a .csv, 3) save it into our directory, 4) opening it in Python using the csv library Pandas. These steps are manually performed, isn't there a way to create a pipeline?

## Pyscopg2

_'Psycopg is the most popular PostgreSQL adapter for the Python programming language. Its core is a complete implementation of the Python DB API 2.0 specifications. Several extensions allow access to many of the features offered by PostgreSQL.'_ Psycopg documentation

Psycopg is a fairly simple to use DBAPI (Database API), you just need to check your server details and the database you want to connect to:

![](https://github.com/AI-Core/Content-Public/blob/main/Content/units/Data-Handling/3.%20SQL/7.%20pyscopg2%20and%20SQLAlchemy/images/psycopg2.png?raw=1)

There are basically 2 objects we need to use to connect to our SQL server: connect and cursor.

- The `connect` object will establish the connection to our database
- The `cursor` object will point to the database, so we can start sending queries to it

Apart from that, we will use some methods from `cursor`:

- `execute` contains the query that we want to perform in a string format
- `fetchall` retrieves the output of the query (use it if you are reading (`SELECT`) entries in your database)
"""

import psycopg2
HOST = 'localhost'
USER = 'postgres'
PASSWORD = #'password'
DATABASE = 'pagila'
PORT = 5432

with psycopg2.connect(host=HOST, user=USER, password=PASSWORD, dbname=DATABASE, port=PORT) as conn:
    with conn.cursor() as cur:
        cur.execute('''CREATE TABLE actor_2 AS (
                    SELECT * FROM actor
                    LIMIT 10);

                    SELECT * FROM actor_2''')
        print(type(cur))
        records = cur.fetchall()

"""In case you don't know the tables inside your database, you can run the following query:
`SELECT table_name FROM information_schema.tables WHERE table_schema = 'public'`
"""

import psycopg2
with psycopg2.connect(host='localhost', user='postgres', password='password', dbname='pagila', port=5432) as conn:
    with conn.cursor() as cur:
        cur.execute("""SELECT table_name FROM information_schema.tables
       WHERE table_schema = 'public'""")
        for table in cur.fetchall():
            print(table)

"""Observe that when you select something, the fetchall method will return a list, which then we have to process into a pandas dataframe. Additionally, if we need to write a sql query such as INSERT INTO, we would need to figure out the correct loop for inserting the proper rows every time we need to insert new data.

A very useful toolkit for this purpose is SQLAlchemy, which simplifies the code. Even though it simplifies the code enormously, SQLAlchemy has more benefits:

1. It is an Object Relational Mapper (ORM), which maps representations of objects to database tables. In other words, this ORM will transform the python objects into SQL tables
2. The second important advantage is the Engine object, which contains information about the type of database (PostgreSQL in this case) and a connection pool. This connection pool allows for multiple connections to the database that operate simultaneously. Additionally, this engine will only work whenever we send a query (Lazy Evaluation)

The syntax is as follows:

```
from sqlalchemy import create_engine

engine = create_engine("{type of database}+{DBAPI}://{username}:{password}@{host}:{port}/{database_name}")
```
"""

from sqlalchemy import create_engine
import pandas as pd
DATABASE_TYPE = 'postgresql'
DBAPI = 'psycopg2'
HOST = 'localhost'
USER = 'postgres'
PASSWORD = #'password'
DATABASE = 'pagila'
PORT = 5432
engine = create_engine(f"{DATABASE_TYPE}+{DBAPI}://{USER}:{PASSWORD}@{HOST}:{PORT}/{DATABASE}")

"""If everything went alright, the next cell should return no error"""

engine.connect()

"""You can also use other methods in the sqlalchemy to inspect the database. In this case, we will use the `inspect` function. This function returns an `Inspector` object, which is a wrapper around the database, and it allows us to retrieve information about the tables and columns inside the database."""

from sqlalchemy import inspect
inspector = inspect(engine)
inspector.get_table_names()

engine.execute('''SELECT * FROM actor''').fetchall()

"""## Making use of the ORM

As mentioned, thanks to the ORM in SQLAlchemy, we can create a table in our database and insert data into it in a simple way.

One way to do so is by using pandas. You can read a specific table from the database using pandas and the engine you just created
"""

actors = pd.read_sql_table('actor', engine)

actors.head(10)

"""Or you can read from a query if you feel like it!"""

actors = pd.read_sql_query('''SELECT * FROM actor LIMIT 10''', engine).set_index('actor_id')
actors

"""You can also use pandas to create tables in your database using the `to_sql` method"""

from sklearn.datasets import load_iris
data = load_iris()
iris = pd.DataFrame(data['data'], columns=data['feature_names'])
iris.head()

iris.to_sql('iris_dataset', engine, if_exists='replace')